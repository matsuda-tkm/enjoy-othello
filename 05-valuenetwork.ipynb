{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 概要\n- このノートブックでは、ValueNetworkを学習させる。\n- ネットワークの構造は以下のとおり。\n    - 入力層：9チャネル\n        - 黒石の位置(1)\n        - 白石の位置(1)\n        - 空白の位置(1)\n        - 合法手の位置(1)\n        - そこに打った場合、何個石を返せるか(1)\n        - 隅の危険領域4マス×4隅をすべて1で埋める(1)\n        - すべて1で埋める(1)\n        - すべて0で埋める(1)\n        - **手番情報：黒番ならすべて0で埋め、白番ならすべて1で埋める**(1)\n    - 第1層：5x5のn_filters種類のフィルターとReLU関数\n    - 第2-11層：3x3のn_filters種類のフィルターとReLU関数\n    - 第12層：3x3のn_filters種類のフィルター\n    - 第13層：1x1のn_filters種類のフィルター\n    - 第14層：出力256個の全結合ネットワークとReLU関数\n    - 第15層：出力1個の全結合ネットワークとtanh関数\n- 学習データの作成方法は以下のとおり。（cf.AlphaGo解体新書p.171）\n    - 1以上60以下の整数からランダムに数字を選択し、これをUとする。\n    - SL-PolicyNetworkをU-1回使って、U-1手目まで局面を進める。\n    - 次のU手目は合法手の中からランダムに選択し局面を進め、この局面をSとする。\n    - 局面Sからは、RLポリシーネットワークを使って、終局まで手を進める。最終的な勝敗をzとする。\n    - 組(S,z)を学習データとする。","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!python -m pip install --no-index --find-links=/kaggle/input/reversi-datasets/ creversi","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:48:45.080012Z","iopub.execute_input":"2023-09-04T23:48:45.080531Z","iopub.status.idle":"2023-09-04T23:48:59.168104Z","shell.execute_reply.started":"2023-09-04T23:48:45.080493Z","shell.execute_reply":"2023-09-04T23:48:59.166963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# リバーシ用ライブラリ\nfrom creversi import Board, move_rotate90, move_rotate180, move_rotate270, move_from_str, move_to_str\nimport creversi\n# 基礎ライブラリ\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom copy import copy, deepcopy\nimport gc\nimport os\n# 学習用ライブラリ\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:07:33.480607Z","iopub.execute_input":"2023-09-05T00:07:33.480993Z","iopub.status.idle":"2023-09-05T00:07:33.488097Z","shell.execute_reply.started":"2023-09-05T00:07:33.480957Z","shell.execute_reply":"2023-09-05T00:07:33.486525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def board_to_array(board):\n    \"\"\"\n    boardオブジェクトからndarrayに変換する関数(PolicyNetwork用)。\n    第1チャンネルは黒石の位置、第2チャンネルに白石の位置、第3チャンネルに空白の位置、\n    第4チャンネルに合法手の位置、第5チャンネルに返せる石の個数、第6チャンネルに隅=1、\n    第7チャンネルに1埋め、第8チャンネルに0埋め。\n    \"\"\"\n    b = np.zeros((8,8,8), dtype=np.float32)\n    board.piece_planes(b)\n    if not board.turn:\n        b = b[[1,0,2,3,4,5,6,7],:,:]\n    b[2] = np.where(b[0]+b[1]==1, 0, 1)\n    legal_moves = list(board.legal_moves)\n    if legal_moves != [64]:\n        n_returns = []\n        for move in legal_moves:\n            board_ = copy(board)\n            n_before = board_.opponent_piece_num()\n            board_.move(move)\n            n_after = board_.piece_num()\n            n_returns.append(n_before-n_after)\n        tmp = np.zeros(64)\n        tmp[legal_moves] = n_returns\n        tmp = tmp.reshape(8,8)\n        b[3] = np.where(tmp > 0,1,0)\n        b[4] = tmp\n    b[5] = np.array([1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., \n                     0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n                     0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                     1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.]).reshape(8,8)\n    b[6] = 1\n    return b","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:49:02.984201Z","iopub.execute_input":"2023-09-04T23:49:02.984844Z","iopub.status.idle":"2023-09-04T23:49:02.997377Z","shell.execute_reply.started":"2023-09-04T23:49:02.984808Z","shell.execute_reply":"2023-09-04T23:49:02.996364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def board_to_array2(board):\n    \"\"\"\n    boardオブジェクトからndarrayに変換する関数(ValueNetwork用)。\n    第1チャネルは黒石の位置、第2チャネルに白石の位置、第3チャネルに空白の位置、\n    第4チャネルに合法手の位置、第5チャネルに返せる石の個数、第6チャネルに隅=1、\n    第7チャネルに1埋め、第8チャネルに0埋め、第9チャネルに手番情報(黒番=0埋め、白番=1埋め)\n    \"\"\"\n    b = np.zeros((9,8,8), dtype=np.float32)\n    board.piece_planes(b)\n    if not board.turn:\n        b = b[[1,0,2,3,4,5,6,7,8],:,:]\n        b[8] = 1\n    b[2] = np.where(b[0]+b[1]==1, 0, 1)\n    legal_moves = list(board.legal_moves)\n    if legal_moves != [64]:\n        n_returns = []\n        for move in legal_moves:\n            board_ = copy(board)\n            n_before = board_.opponent_piece_num()\n            board_.move(move)\n            n_after = board_.piece_num()\n            n_returns.append(n_before-n_after)\n        tmp = np.zeros(64)\n        tmp[legal_moves] = n_returns\n        tmp = tmp.reshape(8,8)\n        b[3] = np.where(tmp > 0,1,0)\n        b[4] = tmp\n    b[5] = np.array([1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., \n                     0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., \n                     0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n                     1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.]).reshape(8,8)\n    b[6] = 1\n    return b","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:49:03.000240Z","iopub.execute_input":"2023-09-04T23:49:03.000617Z","iopub.status.idle":"2023-09-04T23:49:03.013907Z","shell.execute_reply.started":"2023-09-04T23:49:03.000582Z","shell.execute_reply":"2023-09-04T23:49:03.012983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ValueNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        n_filters = 10\n        self.input_layer = nn.Sequential(\n            nn.Conv2d(9,n_filters,kernel_size=5,padding=2),\n            nn.ReLU()\n        )\n        self.hidden_layer = nn.Sequential(\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.ReLU(),\n            nn.Conv2d(n_filters,n_filters,kernel_size=3,padding=1),\n            nn.Conv2d(n_filters,n_filters,kernel_size=1,padding=1),\n            nn.Flatten()\n        )\n        self.output_layer = nn.Sequential(\n            nn.Linear(n_filters*100, 256),\n            nn.ReLU(),\n            nn.Linear(256, 1)\n        )\n        \n    def forward(self,x):\n        out = self.input_layer(x)\n        out = self.hidden_layer(out)\n        out = self.output_layer(out)\n        return out.tanh()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:00:25.657295Z","iopub.execute_input":"2023-09-05T00:00:25.657673Z","iopub.status.idle":"2023-09-05T00:00:25.669965Z","shell.execute_reply.started":"2023-09-05T00:00:25.657640Z","shell.execute_reply":"2023-09-05T00:00:25.668811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学習","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T23:49:03.044267Z","iopub.execute_input":"2023-09-04T23:49:03.044738Z","iopub.status.idle":"2023-09-04T23:49:03.084337Z","shell.execute_reply.started":"2023-09-04T23:49:03.044706Z","shell.execute_reply":"2023-09-04T23:49:03.083590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# N = 2500\n# augmentation = True\n\n# states = []\n# results = []\n\n# for n in tqdm(range(N)):\n#     board = Board()\n#     n_step = 0\n#     while not board.is_game_over():\n#         board_array = board_to_array2(board)\n#         states.append(board_array)\n#         if augmentation:\n#             states.append(np.flip(board_array,axis=2).copy())\n#             for k in range(1,4):\n#                 board_array_rot = np.rot90(board_array, k=k, axes=(1,2)).copy()\n#                 states.append(board_array_rot)\n#                 states.append(np.flip(board_array_rot, axis=2).copy())\n#             n_step += 8\n#         else:\n#             n_step += 1\n#         legal_moves = list(board.legal_moves)\n#         move = np.random.choice(legal_moves)\n#         board.move(move)\n\n#     result = board.diff_num() if board.turn else -board.diff_num()\n# #     results += [result/64]*n_step\n#     if result > 0:\n#         results += [1]*n_step\n#     elif result < 0:\n#         results += [-1]*n_step\n#     else:\n#         results += [-1]*n_step\n\n# states = np.array(states, dtype=np.float32)\n# results = np.array(results, dtype=np.float32).reshape(-1,1)\n        \n# print(f\"boards : {states.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:30:31.905610Z","iopub.execute_input":"2023-09-05T00:30:31.906035Z","iopub.status.idle":"2023-09-05T00:31:07.289585Z","shell.execute_reply.started":"2023-09-05T00:30:31.906001Z","shell.execute_reply":"2023-09-05T00:31:07.287837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n_epoch = 5\n# n_batch = 256\n# lr = 0.001\n# N = states.shape[0]\n\n# seed_everything(1234)\n# model = ValueNetwork().to(device)\n# optim = torch.optim.AdamW(model.parameters(),lr=lr)\n# criterion = nn.HuberLoss()\n# train_loss_list = []","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:31:07.293510Z","iopub.execute_input":"2023-09-05T00:31:07.293820Z","iopub.status.idle":"2023-09-05T00:31:07.311857Z","shell.execute_reply.started":"2023-09-05T00:31:07.293793Z","shell.execute_reply":"2023-09-05T00:31:07.310971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for epoch in range(n_epoch):\n#     train_loss = 0.\n#     np.random.seed(epoch)\n#     random_idx = np.random.permutation(N)\n#     for i in tqdm(range(N//n_batch)):\n#         X_batch = torch.from_numpy(states[random_idx[n_batch*i:n_batch*(i+1)]]).to(device)\n#         y_batch = torch.from_numpy(results[random_idx[n_batch*i:n_batch*(i+1)]]).to(device)\n        \n#         model.train()\n#         optim.zero_grad()\n#         output = model(X_batch)\n#         loss = criterion(output, y_batch)\n#         loss.backward()\n#         optim.step()\n#         train_loss += loss.item()\n#     train_loss /= N//n_batch\n#     train_loss_list.append(train_loss)\n    \n#     # 評価\n#     print(f'Epoch:{epoch+1}/{n_epoch}, train loss:{train_loss:.5f}')\n#     torch.save(model.cpu(), f'ValueNetwork-v1-checkpoint-{epoch+1}.pth')\n#     model.to(device)\n    \n#     # この対局の形勢を判断\n#     moves = \"d3,e3,f2,e2,f5,c5,b6,e6,f6,c6,d6,c4,f3,f7,d7,e7,f4,b5,c3,g5,g6,b4,c7,d2,a6,a5,a3,a4,b3,d8,h6,h5,h4,g4,h3,g3,c2,f1,e1,d1,g2,g1,c1,b7,h1,b1,h2,a2,a8,a7,a1,b2,b8,c8,e8,g8,f8,g7,h8,h7\"\n#     moves = [move_from_str(move_str) for move_str in moves.split(',')]\n#     # iPadアプリの評価と比較\n#     v_app = [0,0,-6,0,-8,0,-19,0,-11,-9,-16,-11,-20,-6,-10,0,-8,0,-18,-9,-10,-8,-7,0,0,0,0,0,-9,0,0,0,6,12,11,12,0,5,0,0,5,15,12,30,31,44,36,54,51,59,44,44,40,40,24,24,24,32,32,32]\n#     v_list = []\n#     model.eval()\n#     board = Board()\n#     for move in moves:\n#         v = model(torch.from_numpy(board_to_array2(board)).unsqueeze(0).to(device)).item()\n#         v_list.append(v*64)\n#         board.move(move)\n#     plt.figure(figsize=(4,1))\n#     plt.plot(v_list, c='red')\n#     plt.plot(v_app, c='blue')\n#     plt.ylim(-64,64)\n#     plt.axhline(0, c='black', ls='--')\n#     plt.title(np.corrcoef(v_list, v_app)[0,1])\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:50:07.283558Z","iopub.execute_input":"2023-09-05T00:50:07.283966Z","iopub.status.idle":"2023-09-05T00:50:07.290538Z","shell.execute_reply.started":"2023-09-05T00:50:07.283935Z","shell.execute_reply":"2023-09-05T00:50:07.289400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"J = 10\n\nn_episode = 2500\naugmentation = True\n\nn_epoch = 10\nn_batch = 256\nlr = 0.001\n\ncriterion = nn.HuberLoss()\n\n###########\nseed_everything(1234)\nmodel = ValueNetwork().to(device)\noptim = torch.optim.AdamW(model.parameters(),lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:47:52.449688Z","iopub.execute_input":"2023-09-05T00:47:52.450320Z","iopub.status.idle":"2023-09-05T00:47:52.455994Z","shell.execute_reply.started":"2023-09-05T00:47:52.450284Z","shell.execute_reply":"2023-09-05T00:47:52.454848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(J):\n    print(f'-----j={j+1}-----')\n    # データ生成\n    states = []\n    results = []\n    for n in tqdm(range(n_episode)):\n        board = Board()\n        n_step = 0\n        while not board.is_game_over():\n            board_array = board_to_array2(board)\n            states.append(board_array)\n            if augmentation:\n                states.append(np.flip(board_array,axis=2).copy())\n                for k in range(1,4):\n                    board_array_rot = np.rot90(board_array, k=k, axes=(1,2)).copy()\n                    states.append(board_array_rot)\n                    states.append(np.flip(board_array_rot, axis=2).copy())\n                n_step += 8\n            else:\n                n_step += 1\n            legal_moves = list(board.legal_moves)\n            move = np.random.choice(legal_moves)\n            board.move(move)\n        result = board.diff_num() if board.turn else -board.diff_num()\n        if result > 0:\n            results += [1]*n_step\n        elif result < 0:\n            results += [-1]*n_step\n        else:\n            results += [-1]*n_step\n    states = np.array(states, dtype=np.float32)\n    results = np.array(results, dtype=np.float32).reshape(-1,1)\n    N = states.shape[0]\n    print(f\"N : {N}\")\n    \n    # 学習\n#     seed_everything(1234)\n#     model = ValueNetwork().to(device)\n#     optim = torch.optim.AdamW(model.parameters(),lr=lr)\n\n    for epoch in range(n_epoch):\n        train_loss = 0.\n        np.random.seed(epoch)\n        random_idx = np.random.permutation(N)\n        for i in tqdm(range(N//n_batch)):\n            X_batch = torch.from_numpy(states[random_idx[n_batch*i:n_batch*(i+1)]]).to(device)\n            y_batch = torch.from_numpy(results[random_idx[n_batch*i:n_batch*(i+1)]]).to(device)\n\n            model.train()\n            optim.zero_grad()\n            output = model(X_batch)\n            loss = criterion(output, y_batch)\n            loss.backward()\n            optim.step()\n            train_loss += loss.item()\n        train_loss /= N//n_batch\n\n        # 評価\n        print(f'Epoch:{epoch+1}/{n_epoch}, train loss:{train_loss:.5f}')\n        torch.save(model.cpu(), f'ValueNetwork-v1-checkpoint-{j+1}-{epoch+1}.pth')\n        model.to(device)\n\n        # この対局の形勢を判断\n        moves = \"d3,e3,f2,e2,f5,c5,b6,e6,f6,c6,d6,c4,f3,f7,d7,e7,f4,b5,c3,g5,g6,b4,c7,d2,a6,a5,a3,a4,b3,d8,h6,h5,h4,g4,h3,g3,c2,f1,e1,d1,g2,g1,c1,b7,h1,b1,h2,a2,a8,a7,a1,b2,b8,c8,e8,g8,f8,g7,h8,h7\"\n        moves = [move_from_str(move_str) for move_str in moves.split(',')]\n        v_app = [0,0,-6,0,-8,0,-19,0,-11,-9,-16,-11,-20,-6,-10,0,-8,0,-18,-9,-10,-8,-7,0,0,0,0,0,-9,0,0,0,6,12,11,12,0,5,0,0,5,15,12,30,31,44,36,54,51,59,44,44,40,40,24,24,24,32,32,32]\n        v_list = []\n        model.eval()\n        board = Board()\n        for move in moves:\n            v = model(torch.from_numpy(board_to_array2(board)).unsqueeze(0).to(device)).item()\n            v_list.append(v*64)\n            board.move(move)\n        plt.figure(figsize=(4,1))\n        plt.plot(v_list, c='red')\n        plt.plot(v_app, c='blue')\n        plt.ylim(-64,64)\n        plt.axhline(0, c='black', ls='--')\n        plt.title(np.corrcoef(v_list, v_app)[0,1])\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:47:53.077902Z","iopub.execute_input":"2023-09-05T00:47:53.078258Z","iopub.status.idle":"2023-09-05T00:49:23.640807Z","shell.execute_reply.started":"2023-09-05T00:47:53.078230Z","shell.execute_reply":"2023-09-05T00:49:23.639708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# moves = \"d3,e3,f2,e2,f5,c5,b6,e6,f6,c6,d6,c4,f3,f7,d7,e7,f4,b5,c3,g5,g6,b4,c7,d2,a6,a5,a3,a4,b3,d8,h6,h5,h4,g4,h3,g3,c2,f1,e1,d1,g2,g1,c1,b7,h1,b1,h2,a2,a8,a7,a1,b2,b8,c8,e8,g8,f8,g7,h8,h7\"\n# moves = [move_from_str(move_str) for move_str in moves.split(',')]\n# v_app = [0,0,-6,0,-8,0,-19,0,-11,-9,-16,-11,-20,-6,-10,0,-8,0,-18,-9,-10,-8,-7,0,0,0,0,0,-9,0,0,0,6,12,11,12,0,5,0,0,5,15,12,30,31,44,36,54,51,59,44,44,40,40,24,24,24,32,32,32]\n# v_mean = np.zeros(len(moves))\n\n# for j in range(J):\n#     model = torch.load(f'ValueNetwork-v1-checkpoint-{j+1}-{n_epoch}.pth')\n#     model.to(device)\n\n#     # この対局の形勢を判断\n#     v_list = []\n#     model.eval()\n#     board = Board()\n#     for move in moves:\n#         v = model(torch.from_numpy(board_to_array2(board)).unsqueeze(0).to(device)).item()\n#         v_list.append(v*64)\n#         board.move(move)\n#     v_mean += np.array(v_list)\n\n# plt.figure(figsize=(4,1))\n# plt.plot(v_mean/J, c='red')\n# plt.plot(v_app, c='blue')\n# plt.ylim(-64,64)\n# plt.axhline(0, c='black', ls='--')\n# plt.title(np.corrcoef(v_list, v_app)[0,1])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-05T00:49:44.732287Z","iopub.execute_input":"2023-09-05T00:49:44.732683Z","iopub.status.idle":"2023-09-05T00:49:45.911680Z","shell.execute_reply.started":"2023-09-05T00:49:44.732649Z","shell.execute_reply":"2023-09-05T00:49:45.910745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}